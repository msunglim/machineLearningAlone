# -*- coding: utf-8 -*-
"""machineLearning10.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1F8ld6EuUtOVVX9E71jlO2pKT2MNY2N7d
"""

import matplotlib.pyplot as plt #draw graph
import numpy as np #make array
from sklearn.model_selection import train_test_split #split array for train/test set
import pandas as pd #use file from url
from sklearn.preprocessing import StandardScaler #make scaled array for multi variables
from sklearn.linear_model import LogisticRegression #predict a value from linear equation with given input..
from sklearn.linear_model import SGDClassifier #stochastic gradient descent. epoch epoch epoch. train train train.
from sklearn.tree import DecisionTreeClassifier #calculate decision tree probability
from sklearn.tree import plot_tree #used when drawing a graph of Decision Tree
from sklearn.model_selection import cross_validate #cross verification which divides a set by 5 subsets for default and test all of them.
from sklearn.model_selection import StratifiedKFold #divide a set by k folds. use for classification. just use KFold for regression
from sklearn.model_selection import GridSearchCV #use cross verification over and over again with different parameter
from scipy.stats import uniform, randint #generate random number for gridsearch params
from sklearn.model_selection import RandomizedSearchCV #greed search for randomly splited cross verification samples.

wine = pd.read_csv('https://bit.ly/wine_csv_data')
# print(wine.head()) return fisrt n rows where default of n is 5.
# wine.info() show csv column information: non null count, dtype
# wine.describe() show column information: count, mean, std, min, max, 25%,50%,75% value

wine_data = wine[['alcohol','sugar','pH']].to_numpy()
wine_target = wine[['class']].to_numpy()
train_input, test_input, train_target, test_target = train_test_split(
  wine_data, wine_target, test_size=0.2, random_state = 42    
)

sub_input, val_input, sub_target, val_target = train_test_split(
    train_input, train_target, test_size = 0.2, random_state = 42
)
# print(sub_input.shape, val_input.shape) #(4157,3) (1040,3)
dt = DecisionTreeClassifier(random_state=42)
dt.fit(sub_input, sub_target)

print("sub score:",dt.score(sub_input, sub_target))
print("val score:",dt.score(val_input, val_target))

scores = cross_validate(dt, train_input, train_target)
print("cross scores:",scores)

print("cross mean score",np.mean(scores['test_score']))

splitter = StratifiedKFold(n_splits= 10, shuffle= True, random_state = 42)
scores = cross_validate(dt, train_input, train_target, cv = splitter)
# print(scores)

print("cross mean score with K Folds",np.mean(scores['test_score']))

# params ={'min_impurity_decrease':[0.0001,0.0002,0.0003,0.0004,0.0005]}
params ={'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001),
         'max_depth': range(5,20,1),
         'min_samples_split': range(2,100,10)}
dt = DecisionTreeClassifier (random_state=42)
gs = GridSearchCV(dt, params, n_jobs = -1)
gs.fit(train_input, train_target)

dt = gs.best_estimator_
print("Gridsearch best_estimator_",gs.best_estimator_)
print("Decision tree score with best params:",dt.score(train_input, train_target))

print("Gridsearch best params:",gs.best_params_)
# print("Gridsearch results:",gs.cv_results_)
print("Gridsearch mean score:",gs.cv_results_['mean_test_score'])

rgen = randint(0,10)
print(np.unique(rgen.rvs(10)))

ugen = uniform(0,1)
print(np.unique(ugen.rvs(10)))

params = {'min_impurity_decrease': uniform(0.0001, 0.001),
          'max_depth': randint(20, 50),
          'min_samples_split': randint(2, 25),
          'min_samples_leaf': randint(1, 25),
          }


dt = DecisionTreeClassifier (random_state=42)
gs = RandomizedSearchCV(dt, params, n_iter=100, n_jobs=-1, random_state = 42)
gs.fit(train_input, train_target)

dt = gs.best_estimator_
print("Gridsearch best_estimator_",gs.best_estimator_)
print("Decision tree score with best params:",dt.score(train_input, train_target))

print("Gridsearch best params:",gs.best_params_)
# print("Gridsearch results:",gs.cv_results_)
print("Gridsearch mean score:",gs.cv_results_['mean_test_score'])