# -*- coding: utf-8 -*-
"""MachineLearning7.py

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1p3hWdpWpYDq2PaEhev4zjKypHYigEvWC
"""

import matplotlib.pyplot as plt #draw graph
from sklearn.neighbors import KNeighborsRegressor #find neighbors for regression
from sklearn.neighbors import KNeighborsClassifier #find neighbors for classification
import numpy as np #make array
from sklearn.model_selection import train_test_split #split array for train/test set
from sklearn.metrics import mean_absolute_error #make scaled array
import pandas as pd #use file from url
from sklearn.preprocessing import PolynomialFeatures #translate inputs for nth dimensional equation
from sklearn.linear_model import LinearRegression #predict a value from linear equation with given input
from sklearn.preprocessing import StandardScaler #make scaled array for multi variables
from sklearn.linear_model import Ridge #predict a value from multi dimensional equation with given input
from sklearn.linear_model import Lasso #predict a value from multi dimensional equation with given input
from sklearn.linear_model import LogisticRegression #predict a value from linear equation with given input..
from scipy.special import expit #calculate probability of negative class
from scipy.special import softmax #calculate probability of multi classes
fish = pd.read_csv('https://bit.ly/fish_csv_data')

fish.head();
# print(fish)

#input datas
fish_input = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy()
# print(fish_input)
#answers
fish_target = fish['Species'].to_numpy() 
# print(fish_target)


# print(kn.classes_) #'Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish' = distinct values from fish_target

#split train/test set
train_input, test_input, train_target, test_target = train_test_split(
    fish_input, fish_target, stratify = fish_target, random_state= len(fish_input)
)


#make sacled arrays
mean = np.mean(train_input, axis=0)
std = np.std(train_input, axis=0)
train_scaled = (train_input-mean)/std
test_scaled = (test_input-mean)/std
# print(test_scaled)

kn = KNeighborsClassifier(n_neighbors =3)
kn.fit(train_scaled, train_target)

ti = np.array(train_input).reshape(-1,5)
tt = np.array(train_target).reshape(-1,)

plt.scatter(ti[:,0], tt)
plt.show()

print(kn.predict(test_scaled[:5])) #['Bream' 'Perch' 'Perch' 'Perch' 'Bream'].. 
# print(test_scaled[:5])#return 0~5th rows of test_scaled

proba = kn.predict_proba(test_scaled[:5])
print("kn_predict_proba",np.round(proba, decimals =4))

bream_smelt_indexes = (train_target =='Bream') | (train_target == 'Smelt')
# print(bream_smelt_indexes)

train_bream_smelt = train_scaled[bream_smelt_indexes]
# print(train_bream_smelt)
target_bream_smelt = train_target[bream_smelt_indexes]
# print(target_bream_smelt)

lr = LogisticRegression()
lr.fit(train_bream_smelt, target_bream_smelt)

print(lr.predict(train_bream_smelt[:5]))
print("lr_predict_proba binary",lr.predict_proba(train_bream_smelt[:5]))
print(lr.coef_, lr.intercept_) #[[-0.41581543 -0.59429439 -0.68212298 -1.02045413 -0.76459742]] [-2.25744997]

decisions = lr.decision_function(train_bream_smelt[:5]) # = a* wei  + b*len + c*dia + d*hei + e*wid + f
print("Z:",decisions) 

print("probability of negative class",expit(decisions))

#multi regression
lr = LogisticRegression(C=20, max_iter= 1000) #max_iter: # of repeat. default is 100. As C increases, regulation decreases.
lr.fit(train_scaled, train_target)

print(lr.score(train_scaled, train_target)) #0.9411764705882353
print(lr.score(test_scaled, test_target)) #0.875

proba = lr.predict_proba(test_scaled[:5])
print("lr.predict_proba multi",np.round(proba, decimals = 3))

print(lr.coef_.shape, lr.intercept_.shape) #(7, 5) where 7 = # of rows(classes), 5 = # of columns(coefs). (7,)
print("coef, intercpet",lr.coef_, lr.intercept_) #Where 7 is # of classes (Species, target), 5 is # of attributes(Weight, Length, Diagonal, Height, Width. input)

decision = lr.decision_function(test_scaled[:5]) 
print("Z:",np.round(decision, decimals= 2)) #returns Z value. = a* wei  + b*len + c*dia + d*hei + e*wid + f

proba = softmax(decision, axis=1)
print("softmax",np.round(proba, decimals=3)) #= predict_proba! #calculate probability with softmax using Z values(decision)

