https://colab.research.google.com/?hl=ko

접속 취소하고 
연결 ->  호스팅된 런타임연결

컨트롤 엔터로 실행
알트 엔터로 실행 후 아래줄이동
시프트 엔터로 아랫줄로이동

구글드라이브나 github에 저장가능'

사용하게될 라이브러리는 sklearn , tensorflow다.

런타임은 평소에는 none이지만 tensorflow쓸땐 GPU로 설정.

1. 그래프만들기
import matplotlib.pyplot as plt

bream_length = [25.4,26.3,26.5,29.0,29.0,29.7,29.7,30.0,30.7,30.9,31.0,31.0,31.5,32.0,32.0,33.0,33.5,33.5,34.0,34.0]
# print(len(bream_length))
bream_weight= [430.3,450.0,500.0,390.0,450.0,500.0,475.0,500.0,500.0,340.0,600.0,600.0,700.0,700.0,610.0,650.0,575.0,685.0,620.0,680.0]

plt.scatter(bream_length, bream_weight)
plt.xlabel('length')
plt.ylabel('weight')

plt.show()

신기하다. 원리는 plt.scatter(X축, Y축) 과 show

하나의 그래프에 여러개의 데이터를 넣을 수 있다. 그럼 알아서 색깔도 다르게해줌
plt.scatter( data1, data1_)
plt.scatter(data2, data2_) 

2. 데이터합치기 for 분류 (Classifier)

length = bream_length + smelt_length
weight = bream_weight+ smelt_weight

fish_data =[[l,w] for l, w in zip(length, weight)]

이렇게하면 [  [l1, w1].... [ln, wn]]  2 dimensional array가 만들어져.

이렇게합쳐놓고, 뭐가 뭔지 지정을 해줘야해. (정답지)

fish_target = [1]*len(bream_length) + [0]*len(smelt_length) 이렇게하면 bream은 1로써 저장되고 smelt는 0으로써 저장되겠지. 찾을려는 정보를 1로 놓는게 좋다. 
[1,1,1,1,1,1,1,1,0,0,0,0,0,0,0] 이런모양이 돼.

***numpy의 기능을 이용해 간단하게 표현할 수 있다.***
# fish_data =[[l,w] for l, w in zip(length, weight)]
fish_data = np.column_stack((length, weight))
 col1에 길이 데이터, col2에 무게 데이터를 넣는다는뜻.
[ [ l1, w1 ], 
   [l2, w2]...] 이렇게 저모양으로 스텍이쌓이네요


# fish_target = [1]*len(bream_length) + [0]*len(smelt_length)
fish_target = np.concatenate((np.ones(len(bream_length)), np.zeros(len(smelt_length))))

np.ones/zeros(N)이면 N개의 1로 이루어진 arr를 생성
np.concatenate(arr1, arr2)는 arr1과 arr2를 합침

3. K-최근접이웃
from sklearn.neighbors import KNeighborsClassifier

kn = KNeighborsClassifier()

//machine learning model
kn.fit(fish_data, fish_target)   
반반나눈 data와 target을 묶는다.. data값일때 정답은 target이게.. 

//그냥 얼마나 잘맞추는지. 1= 100%정답률. = 여기선 당연히 그래야하는게 섞을때 같은 index로했기때문에.. 예를들어 data[n]가 '대한민국'였을경우 target[n]='Korea'이기때문에 항상일치.
kn.score(fish_data, fish_target)

 새로운 데이터를 주고 어느 집단에속하는지 알게하는법

kn.predict([[2, 10]])
이렇게주면 0이나오고 [[30,600  ]] 이런걸로주면 1로나옴.! 가장 가까운 이웃들이 어떤 데이터인지 보고 주어진 데이터의 값도 이웃들과 비슷하겠거니함.. 


4. 정확도
kn.predict([[30, 500]])

kn49 = KNeighborsClassifier(n_neighbors = (len(bream_length)+len(smelt_length)))
kn49.fit(fish_data, fish_target)
kn49.score(fish_data, fish_target)

이것은 58퍼센트의 확률로 bream이나옴. 왜냐면 bream데이타수/총 데이터수 = 0.58이기때문에. 위에꺼랑다른것은, ()일경우에는 바라보는데이터가 정의되지않아서..? 1:1로 대응하면 전부 자기랑 정답이니까.. 근데 2번째거처럼 모든데이타를 바라보면, 1인건 정답이지만 0인건 오답이라..?

5. train/test set

train_input/target과 test_input/target을 분리한다.
연습할때는 train, 실험해볼때는 test로 해본다.

*여기서 A집단은 array = [, , , ]이고 fish_data= A집단+ B집단.

train_input = fish_data[:len(A집단)]
train_target =fish_target[: len(A집단)]

test_input = fish_data[len(A집단):]
test_target = fish_target[len(A집단):]

kn = KNeighborsClassifier()
kn = kn.fit(train_input, train_target)

kn.score(test_input, test_target)

대신 이렇게하면, train할때와 test할때 데이터가 딴판일수 있기때문에, (A집단으로 훈련했는데, 정작 물어보는건 B집단이라, A,B를 골고루 섞어야할 필요가있음)

numpy를 이용해야한다.

import numpy as np

input_arr = np.array(fish_data)
target_arr = np.array(fish_target)

np.array하지않았을때는 [ [] , [] , [] ] 의 모양을 가지지만
np.array를하면 쉼표가 사라지고
[
[]
[]
[]
]의 모습을 가진다
 
index = np.arange(len(A+B집단))     #arange(N)은 0~N까지의 숫자로 이루어진 array생성. 0번째 index엔 0, 1th index엔 1....  
np.random.shuffle(index)  #저 어레이를 랜덤하게 섞음. 

이것을 해준후,
train_input = input_arr[index[: len(A집단)]]        
train_target = target_arr[index[:len(A집단)]]

test_input = input_arr[index[len(A집단): ]]
test_target = target_arr[index[len(A집단): ]]

#원리는, index[: k]로 무작위의 인덱스배열중 0~k까지 불러들여.
그리고 input_arr[ a,b,c]를 해주는데 이것은 [input_arr[a],input_arr[b],input_arr[c]]하는것과같음
#이것들은 배열 슬라이싱인데, input_arr 의 index[0:a집단의수]면 (index에있는 0~집단의 수th 번째 원소에 해당하는 값)번째에 있는 input_arr의 원소들을 반환해

예를 들면
a= np.array([5,6,7,8])
print(a[[1,3]]) 이거하면, 6,8이 불려나와.

이렇게한것을
plt.scatter(train_input[:,0], train_input[:, 1])
plt.scatter(test_input[:,0], test_input[:,1])
plt.xlabel('length')
plt.ylabel('width')
plt.show()
로 테스트해볼수 있는데, 이러면 train과 test가 잘 섞인것을 볼 수 있어.

여기서 train_input[: ,0]이런게 있을텐데  [a:b, c:d]라고하면 a~b까지 row, c~d까지의 col을 선택하는건데 예제에서는 , 앞에는 0~모두라 생략함. 그리고 ,뒤에는 0번째 col만 선택하는건데, 이번예제에서는 [[길이, 넓이], [길이, 넓이]...] 이런식으로 약속이 되있기때문에, 길이만 전체선택한다고 볼 수 있다.

: 는 모두를 의미
, 앞의 수는 row을 의미
, 뒤의 수는 col을 의미

따라서 모든 1번째 col선택은 arr[ :, 1]이 되겠다.

6. numpy와 sklearn으로 세련된 코딩하기
***numpy의 기능을 이용해 간단하게 표현할 수 있다.***
# fish_data =[[l,w] for l, w in zip(length, weight)]
fish_data = np.column_stack((length, weight))
 col1에 길이 데이터, col2에 무게 데이터를 넣는다는뜻.

# fish_target = [1]*len(bream_length) + [0]*len(smelt_length)
fish_target = np.concatenate((np.ones(len(bream_length)), np.zeros(len(smelt_length))))

np.ones/zeros(N)이면 N개의 1로 이루어진 arr를 생성
np.concatenate(arr1, arr2)는 arr1과 arr2를 합침

ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ
from sklearn.model_selection import train_test_split


train_input, test_input, train_target, test_target = train_test_split(
    fish_data, fish_target, stratify= fish_target, random_state=len(fish_data))

이렇게해주면, 
train_input과 test_input 이 나뉘고 train_target과 test_target이 나뉜다.
stratify가 fish_target의 데이터를 보고 그것들이 골고루 섞일 수 있도록 섞는다. 그래서 1,0밖에없는 target이 골고루 섞인상태가되고 마지막 random_state로 어느 한기점을 중심으로 반토막내버려. 그 반토막을 기준으로 train과 test 집단이 나뉘게 되는데, 자연스래 train과 test 값들이 골고루 쪼개질 수 밖에없다.


입력데이터로부터 가까운 이웃까지 거리와 가까운 이웃의 좌표를 반환한다.
이때 가까운 이웃은 kneighbor에 기반한다. kneighbor의 기본값은 5이다.
#returns distance from point to its neighbors and indexes of neighbors based on Kn_neighbors 
distances, indexes = kn.kneighbors([[25,150]])
# print(distances) index is generated based on the graph.
# print(indexes)
[[130.48375378 138.37485321 140.64938677 140.72046759 140.81068851]]
[[ 3 23 16 22 21]] 이런 형식으로.


plt.scatter(train_input[:,0], train_input[:, 1])
# mark triangle on input point 삼각형으로 입력값의 좌표를 표시한다.
plt.scatter(25,150, marker= '^')

# mark diamond on points close to input point 다이아몬드로 가까운이웃을 표시한다.
plt.scatter(train_input[indexes,0], train_input[indexes,1], marker='D')

이렇게했을때, 육안으로 봣을때 가까운 이웃들이 선택되지않았다면 그것은 아마 그래프 스케일의 문제일 것이다. 예를들어 x: 0~10 이고 y:0~1000이라면, 육안으로 비율이 같게 정사각형모양의 그래프에서는 5,500은 6,700 이 더 가까워보일 수 있지만 실제로는 1,400이 더가깝다. 스케일 조정으로 이런 치사한 오류를 피할 수 있다. 

plt.xlim( min, max) 로 y축에맞게 x축을 조절해보자. 그럼 왜 이런일이 있는지 알 수 있다.

표준점수로 바꿔 이 문제를 해결해보자.
mean = np.mean(train_input, axis=0)
std = np.std(train_input, axis=0)

train_scaled = (train_input - mean)/std

mean의 크기는 train_input과 같기때문에 바로위의 코드를 실행하면 모든 train_iput에서 mean의 값을 빼주고 std로 나눠준다.

test_input의 값들 또한 평균/표준편차를 이용해 scale을 맞춰준다.


kn = kn.fit(train_scaled, train_target)
test_scaled = (test_input - mean)/std
kn.score(test_scaled, test_target)

입력값또한 scale을 맞춰준다.

new = ([25,150]- mean)/std
distances, indexes = kn.kneighbors([new])

그리고 맞춰진 애들을 가지고 새로운 그래프를 그려보자

plt.scatter(train_scaled[:,0], train_scaled[:, 1])
# mark triangle on input point
plt.scatter(new[0], new[1], marker = '^')
# mark diamond on points close to input point 
plt.scatter(train_scaled[indexes,0], train_scaled[indexes,1], marker='D')

plt.xlabel('length')
plt.ylabel('weight')
plt.show()

이렇게하면 육안으로도 공감/이해할 수있는 이웃들이 다이아몬드로 마크된다. 
이렇게 스케일을 맞춰주는 작업을 전처리 작업이라고한다. tree에서는 할 필요가 없다고한다.

7. 회귀(regression)에는 target값을 맞출 필요가없다.예측값이기때문에 이미있는 값(위에서 target [1,0])이아니라 새로운값을 예측하기때문에. 
왜 회귀라고 부르냐면 콜턴이라는 애가 19세기에 키 큰 부모의 자식이 그정도로 키가 크기않고 동년배 평균값의 키로 회귀하드라 라고 예측을 한 논문에서 regression이라는 단어가 굳어졌다...

위의 방식 (최근접분류)과 회귀가 다른것은 최근접분류는 가까운 이웃이 ㅁ,ㅁ,ㅅ이면 타겟의 값은 ㅁ으로 분류하는거고
최근접회귀는  만약 가까운이웃이 10 20 30 이라는 값을 가지고 있다면 [10+20+30]/ 3 = 20 의 값으로 예측하는거다. 

8. 회귀문제에선 stratify 가 필요없다.
#we don't need stratify for regression.
train_input, test_input, train_target, test_target = train_test_split(
    perch_length, perch_weight, random_state= 20
)
이러면 perch_length를 train과 test input이 나눠먹고, perch_weight를 train과 test target이 나눠먹어. 
classification에선 
[
 [], 
 []
] 이렇게나뉘었다.

여기서 왜 모양이 1자로 나오나면, perch_length가 그냥 [ , , ,]형식의 데이터였기때문이야. 저 위에서 classifier할때는 fish_data = np.column_stack(length, width)해서 stack모양으로 만들어줬음.

이러면 모양이 [ [v1,v2] , [v3,v4], .....]이런모양이나오기때문에, 
[
[v1,v2],
[v3,v4]
...
]
이렇게 하고싶다면 reshape를 써라. -> knr.fit에 필요함. 

train_input = np.array(train_input).reshape(-1,1)
test_input = np.array(test_input).reshape(-1,1)

reshape( 줄 갯수,1 set당 원소의 갯수)
줄 갯수가 -1일경우, 알아서 해라라는뜻? 

from sklearn.neighbors import KNeighborsRegressor

knr = KNeighborsRegressor()
knr.fit(train_input, train_target)

knr.score(test_input, test_target)
이걸로 정확도 테스트를 할 수 있는데, 그 공식은 R^2 = 1 - (sum of (target-input)^2 )/(sum of(target-mean)^2) 라고한다. 식을보면, 분수중 위의 target-input값이 0이면, 뺄셈의 값이 1이기때문에 매우 정확하게 된다는걸 알수 있고, 분자와 분모의 값이 같아질수록 뺄셈의 값이 0이기때문에 정확도가 떨어진다는것을 알수 있다. 다시말하면 예측값이 평균과 같아질수록 정확도는 떨어진다..?ㄷㄷ

9. 오차
아래코드는 오차값을 나타내준다.
**예제들에서 input = 길이 target=무게 였던것을 상기하자.

from sklearn.metrics import mean_absolute_error
test_prediction = knr.predict(test_input)
mae = mean_absolute_error(test_target, test_prediction)

결과)
[[33.5]  print(test_input)
 [32. ]
 [31. ]
 [29. ]
 [26.3]]
[675.0, 615.0, 600.0, 450.0, 450.0]  print(test_target)
[649.   602.   550.   493.   471.06] print(test_prediction)
30.612000000000013 print(mae)


코드를보면 test_prediction은 test_input (length)값에 기초해서 weight를 예측한다. 그것이 실제 target (weight)값과 비교했을때 오차가 좀 있는데, 그것이 mae이다. 

10. 과대적합/ 과소적합
print("train score:",knr.score(train_input, train_target) , "\ntest score",knr.score(test_input, test_target))
과소적합 (underfitting): train score < test score. 연습할때보다 실제시험에서 더 잘맞춤
과대적합 (overfitting): train score > test score.  연습할땐 잘했는데 실제시험 조짐

해소법은 knr.n_neighbors를 조절하면된다. 기본값이 5인데, 그것보다 높으면 과소적합, 낮으면 과대적합 
k가 높아질수록 train때보다 test값이 커진다. 
k가 낮아질수록 train때보다 test값이 작아진다.

11. 코렙에서 새로운 노트북을 해야 새로운 파일이 드라이브에 저장된다. 그렇지 않으면 계속하나의 파일에 덮어쓰기하는거임..

12. MachineLearning 5
최근접이웃에 문제점은 샘플범위밖의 수치가 주어졌을때, 그 값에 대한 결과를 주는게아니라, 걔랑 근접한 이웃을 참고해서 값을 반환하기때문에, y = x라는 그래프를 가지고 있어도 샘플이 [0~10]만 주어지고 실제 인풋은 100이라면 100을 반환하는게아니라 10을 반환함. 10이가장 가까운친구이기 때문에.

선형회귀 (linear regression)을 써야한다.
from sklearn.linear_model import LinearRegression

lr = LinearRegression()

lr.fit(train_input, train_target)

coef = np.array(lr.coef_).reshape(-1,)
intercept = np.array(lr.intercept_).reshape(-1,)
print("y = ", coef,"x + ", intercept) #coef와 intercept는 [[a]]의 형태를 가지고있다.

predicted_weight = lr.predict([[input_length]])
print("linear regression:", predicted_weight)
plt.scatter(train_input, train_target)
plt.scatter( input_length, predicted_weight, marker ='^')
plt.show()

이것에 대한 결과는 이미지파일로 저장해두었다. 아주 강력한기능이다. knr은 그 주변 이웃들의 결과의 평균을 산출했다면, linear은 데이터들을 그래프로 그리고 그것에 대한 기울기와 절편을 구해서 x에 input값을 대입해서 y를 구하는 느낌이다.

ymin = 20*coef + intercept
ymax = 40*coef + intercept
print(ymin, ymax)
plt.plot([20, 40], [ymin, ymax])
그래프를 그릴 수 있다. 꼭 reshape(-1, )를 해줘야. 줄갯수가 0이되기때문에 2차원배열이아니라 1차원배열로 된다. 그래야 plot을 그릴 수 있어. 20은 데이터의 가장작은 값보다 작은값 40은 가장큰값보다 큰값으로 설정해서 그래프의 나아가는 방향을 나타내고자했다.

단점이라면 선형그래프이기때문에 음수가 나올 수 있다는점.그리고 곡선은 표현하지않는다는점..

13. 그래서 배우는 다항회귀 (2차,3차.,.ㅜㅜ)

2차원그래프그리는 식이,, y = ax^2 + bx + c 라고한다.. 파이썬에서 제곱은 **2로표현한다.
train_poly = np.column_stack((train_input**2, train_input))
test_poly = np.column_stack((test_input**2, test_input)


lr = LinearRegression()
lr.fit(train_poly, train_target)

predicted_weight_poly = lr.predict([[input_length**2, input_length]]) #입력값을 사용한 예측값

coef_poly = np.array(lr.coef_).reshape(-1,)       #반드시 이렇게 해야 plot으로 그릴 수 있음. 1차원化
intercept_poly = np.array(lr.intercept_).reshape(-1,)

plt.scatter(train_input, train_target) #학습데이터 그래프에 표시하기
plt.scatter(input_length, predicted_weight_poly, marker ='^') #예상지점 ^으로 표시하기

print(coef_poly ,intercept_poly) #[2.90924793 -142.59537447] [2179.20603384]
point = np.arange(20,40) #20은 데이터상 가장작은값보다 작은값 40은 가장큰값보다 큰값. plot에서 선형일때는 [20,40]안에서 내맘대로 쭉긋고쓰면 됐지만 선형이라 모든 포인트가 필요해서이렇게 쓰는듯하다. 선형은 시작지점, 끝지점을 정했잖아.
plt.plot(point, coef_poly[0]*point**2 +coef_poly[1]*point + intercept_poly) # y = ax^2+bx+c where a =coef[0], b= coef[1], c= intercept.

#print(lr.score(train_poly, train_target))
#print(lr.score(test_poly, test_target))
plt.show()


14. MachineLearning 6.
3개의 특성(Attributes)이 주어졌을때 예측..
import pandas as pd

df = pd.read_csv('https://bit.ly/perch_csv')

print(df) #0      8.4     2.11    1.41 이런형태야. index length height width
perch_full = df.to_numpy()

print(perch_full) [ [ 8.4   2.11  1.41], [] ...] 이런형태로 바꿔줘. 근데 이거 stack이 되어있음.

이런 코드로 남이 업로드해논 데이터를 가져올 수 있다. 그리고 to_numpy()를 이용해 2차원배열로 바꿀 수 있어.
판다스는 엑셀맹키로 생긴 파일을 읽어올 수 있다네. 시각화기능도있다고함.

PolynomialFeature를 Transformer라 부르고 LinearRegression, KNeighbors를 Estimuator라고부른다.
Transformer: fit -> transform
Estimator: fit -> predict-> score

from sklearn.preprocessing import PolynomialFeatures
poly = PolynomialFeatures()
poly.fit([[2,3]])
print(poly.transform([[2,3]])) #[[1. 2. 3. 4. 6. 9.]]

poly.fit([[a,b]]) -> poly.transform([[a,b]]) 의 결과는 [[1, a, b, a^2, a*b ,b^2]]

train_input, test_input, train_target, test_target = train_test_split(
    perch_full, perch_weight, random_state= len(perch_full)
)
train_input = np.array(train_input).reshape(-1,3) #주의할점은 -1,3이라는것. 3은 한 줄에 3개의 특성이 다 담겨있다는것이야. 이래야지만 train_poly.shape가 42, 9 이렇게나옴.
test_input = np.array(test_input).reshape(-1,3)
#do this, otherwise we have typeerror: only integer scalar arrays can be converted to a scalar index site:stackoverflow.com
train_target = np.array(train_target).reshape(-1,1) #여기는 -1,1로해주는게중요하다. 왜냐면 얘네들은 무게의 데이터를 가지고 있기때문에 한줄에 1개의 값만들어간다. 

#귀찮아서 false로 해준다함.. 1을 굳이할 필요없어서?
poly = PolynomialFeatures(include_bias= False) #기본degree는 2이다.
poly.fit(train_input) #(42, 9) 42개의 행, 9개의 열(특성) 밑에거.
train_poly = poly.transform(train_input) #['x0' 'x1' 'x2' 'x0^2' 'x0 x1' 'x0 x2' 'x1^2' 'x1 x2' 'x2^2'] 모든 특성이 다들어가 융합된모습이야. a,b,c,a^2, ab,ac,b^2,bc,c^2 의 모습
>

test_poly = poly.transform(test_input) #훈련세트를 변환한거맹키로 테스트세트도 변환해주는 습관을 들여라.

poly = PolynomialFeatures(degree=5, include_bias= False) 이렇게 degree를바꾸면
print(train_poly.shape) #(42,55)가되고 
print(lr.score(train_poly, train_target)) 하면 0.9999999975216065 라서 잘나오는데..
print(lr.score(test_poly, test_target)) 하면 -44816.57139864114 곱창난다. 

너무이렇게 과대적합으로 곱창나면 규제(정규화)를 해줘야한다. 가중치(기울기)를 작게한다. 

from sklearn.preprocessing import StandardScaler
ss = StandardScaler();
ss.fit(train_poly) #여기서 표준편차를 구한다음

train_scaled = ss.transform(train_poly) #여기서 알아서 스케일 맞춰준다. 아마(x-mean)/std겟지
test_scaled = ss.transform(test_poly)

KNeightbor할때 스케일을 맞췄던것처럼 Regression에도 그래줘야한다. 스케일을 맞추고나서
그리고 LinearRegression에 평가를 요구하기보다 Ridge에 평가를 받아본다. 릿지는 가중치의 제곱을 기준으로 계산한다.
from sklearn.linear_model import Ridge
ridge = Ridge() #default alpha =1. 높아질수록 감도가올라가는데 베스트감도는 일일히 맞춰갈 수 밖에없음
ridge.fit(train_scaled, train_target)

print(ridge.score(train_scaled, train_target))
print(ridge.score(test_scaled, test_target)) #둘다 95퍼센트의 정확도를 가짐


plt.scatter(train_poly[:,0], train_target)
plt.scatter(train_poly[:,1], train_target)
plt.scatter(train_poly[:,2], train_target)
plt.show()

plt.scatter(train_scaled[:,0], train_target)
plt.scatter(train_scaled[:,1], train_target)
plt.scatter(train_scaled[:,2], train_target)
plt.show()

스케일을 맞춘것과 안맞춘것의 그래프 차이는 이미지로 저장되었다. scale을 맞추지않은것은 자기값에 따라 나아가는 방향과 기울기가 다르지만, 스케일을 맞추고나서는 단일화하여 하나의 비슷한 방향으로 가는것으로 관측된다.

베스트 값을 찾는 법은, 

alpha_list = [0.00000001,0.0000001,0.000001,0.00001,0.0001,0.001,0.01,0.1,1,10,100,1000]
train_score_list = []
test_score_list = []
for alpha in alpha_list:
  ridge = Ridge(alpha=alpha)
  
  ridge.fit(train_scaled, train_target)
  train_score_list.append(ridge.score(train_scaled, train_target))
  test_score_list.append(ridge.score(test_scaled, test_target))

plt.plot(np.log10(alpha_list), train_score_list)
plt.plot(np.log10(alpha_list), test_score_list)
plt.show()
이렇게 그래프를 그리고, 가장 서로의 그래프의 간격이 적은 쪽의 alpha값을 취한다. 왼쪽으로 갈수록 과대적합이고 오른쪽으로 갈수록 과소적합이된다. 왼쪽으로 갈 수록 훈련세트 위주로 훈련을 하는거니까 실제 값은 훈련세트랑 다르니까 빗나가는거임. 반대로 오른쪽으로 갈 수록 훈련세트를 무시하니까 훈련세트의 정확도가 감소.
alpha가 규제인데, 규제가 커질수록 과소적합, 적어질수록 과대적합이라고한다.

Lasso 회귀라는것도 있는데, 이것은 가중치의 절대값으로 계산한다.

from sklearn.linear_model import Lasso
#Lasso Regression
lasso = Lasso(alpha=1)
lasso.fit(train_scaled, train_target)

print(lasso.score(train_scaled, train_target))
print(lasso.score(test_scaled, test_target))
print("# of attributes using Lasso: ",np.sum(lasso.coef_==0)) 이것을 통해 몇개의 특성이 Lasso에 영향을 받는지 알 수 있다. 예를들어 특성 55개중 이 값이 40일경우, 15(55-40)개만 Lasso회귀를 사용하고 나머지는 사용하지않는다는것을 의미한다. 

베스트 알파값을 찾는것의 방법은 릿지때와같다.

#find Best alpha value 
alpha_list = [0.001,0.01,0.1,1,10,100,1000]
train_score_list = []
test_score_list = []
for alpha in alpha_list:
  lasso = Lasso(alpha= alpha)
  
  lasso.fit(train_scaled, train_target)
  train_score_list.append(lasso.score(train_scaled, train_target))
  test_score_list.append(lasso.score(test_scaled, test_target))

plt.plot(np.log10(alpha_list), train_score_list)
plt.plot(np.log10(alpha_list), test_score_list)
plt.show()

이로써 LinearRegression, Ridge, Lasso를 알아보았다. 각각 score를 메길 수 잇는것을 확인했다. 아마도 하는 이유는 훈련데이터를 자기나름대로 분석해서 예측값를 얻기위함인것같다... 미래예측할때 자기가 가장 신뢰하는 방법을 사용하는 건가보다.  그런데, 특성(Attributes)이 2개이상인것을 쓸때는 LinearRegression을 쓰지말것이 권장되는듯하다.. 아마 과대적합문제일텐데, Ridge와 Lasso는 그 문제가 적다.대신에 어떤 방법을 쓰든 예측값은 대충 비슷하게나온다.Ridge와 Lasso의 예측값은 그들의 alpha 에 따라 달라지는데, 최선의 알파값은 위의 공식에서 찾을 수 있다. 
*degree가 달라짐에따라 LR도 붕괴하는것을 확인했다. 그냥 Ridge나 Lasso를쓰자.얘네들의 값은 꽤 잘맞춘다.

1줄의 배열은 scale할수없다. 왜냐면 scale의 공식이 (value-mean)/std인데, 여기서 mean이 첫줄의 mean과 같아서 0으로 된 배열을 반환할뿐이다. 따라서 predict할때는 저것을 따라라.
l = 28.4
h = 7.11
w = 4.14
list = np.array([l,h,w]).reshape(-1,3)

poly.fit(list)
input = poly.transform(list)
그리고 poly를 쓴다면, (아마 여러개의 attributes를 쓸때그러겠지), 반드시 실험값도 poly로 전개해줘야한다. 전개를하면 degree에 맞는 형식의 array를 만들수있다. 예를 들어 degree= 2에서는 ['x0' 'x1' 'x2' 'x0^2' 'x0 x1' 'x0 x2' 'x1^2' 'x1 x2' 'x2^2'] 


15. machineLearning7 
럭키백 =  x%확률로 A가 나온다. 메이플 부화기같은거지
분류문제: 왜냐면 인풋값이 주어졌을때 그것의 속성을 맞추는거기때문임. 그것의 값을 계산하는게아니라. 로지스틱회귀(LogisticRegression)이라는 이름을사용하지만 회귀라기보단 분류에 가까움... 공집합모양 = 1/(1+e^(-z)) 을 시그모이드라고 부른다.

판다로 데이터를 url로부터 불러올수있음. 
 fish_input = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy() 이런게있는데
이것은 fish 배열의 weight, legnth, diagonal, height, width Column들의 값을 가져오는거임. ㄷ

fish가 [ 
	[species ,weight  ,length  ,diagoanl  ,height  ,width]
   ] 이렇게생겻는데 해당되는 [모든열][가져올것이름] 하면
 그쪽값만 이런모양으로 ->[ 
[],
[].. ] 가져오는듯..

*Split train/test set은 이제 너무나 당연해서 설명조차안한다.
#split train/test set
train_input, test_input, train_target, test_target = train_test_split(
    fish_input, fish_target, stratify = fish_target, random_state= len(fish_input)
)

*scale맞추는것도 너무 당연해서 설명안하는듯
#make sacled arrays
mean = np.mean(train_input, axis=0)
std = np.std(train_input, axis=0)
train_scaled = (train_input-mean)/std
test_scaled = (test_input-mean)/std

*그래프로 그림그리기할려면 반드시 reshape해줘야함

ti = np.array(train_input).reshape(-1,5)
tt = np.array(train_target).reshape(-1,)

plt.scatter(ti[:,0], tt)
plt.show()

이렇게하면 등록된 target중에서 distinct한 값만 반환해줌. 이번 데이터타겟은 string의 값들인데 자동으로 숫자로 변환해준다함. 
print(kn.classes_) #'Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish' = distinct values from fish_target 알파벳순서임ㅋ

print(kn.predict(test_scaled[:5])) #['Bream' 'Perch' 'Perch' 'Perch' 'Bream']..
처음다섯개의 예상값을 물었는데 숫자로 주는게아니라 영어로 다시 바꿔서 돌려줌.
# print(test_scaled[:5])#return 0~5th rows of test_scaled
근데 이렇게하면 그냥 숫자값을 줘버려..

proba = kn.predict_proba(test_scaled[:5]) 하면 각행별로 어떤 확률로 어떤클래스에 분류되는지 보여줌.
[[1.     0.     0.     0.     0.     0.     0.    ] 100%확률로 0th = 100% 확률로bream
 [0.     0.     0.6667 0.     0.3333 0.     0.    ] 66%확률로 Perch, 33%확률로 Roach!
 [0.     0.     0.6667 0.     0.3333 0.     0.    ]
 [0.     0.     1.     0.     0.     0.     0.    ]
 [0.3333 0.     0.3333 0.     0.     0.     0.3333]]

좀더 그럴싸한 확률얻는 방법은 로지스틱회귀라는게있따.

z= a* wei  + b*len + c*dia + d*hei + e*wid + f 이런식으로 사용한다고한다.
그대로사용하면 그냥 회귀가 되므로 [-oo, oo] 범위를 [0,1]로 바꿔줘야함

1/(1+e^-z)의 값이 0.5 초과이면 양성 , 0.5이하면 음성클래스라고한다.

그냥 이건 z의 값이 0보다 작으면 음성 0보다크면 양성이다. 왜냐면 e^-z = 1/e^z인데 z가 커질수록 이값은 0이되므로 1/(1+0) = 1 = 양성. 

어떤 array에서 특정값을 가진 index만 뽑아 내고 싶다면,,?
bream_smelt_indexes = (train_target =='Bream') | (train_target == 'Smelt')
# print(bream_smelt_indexes)
-> true, false로 이루어진 array 변환. bream이나 smelt면 true.

저기서 true라고 된 index만 추출하기. true라고 적힌 index = train_scaled에서 뽑을 row index
train_bream_smelt = train_scaled[bream_smelt_indexes]
# print(train_bream_smelt)
target_bream_smelt = train_target[bream_smelt_indexes]
# print(target_bream_smelt)

선형모델을 쓸때 LinearRegression쓰는거맹키로 로지스틱써도됨
from sklearn.linear_model import LogisticRegression #predict a value from linear equation with given input..
lr = LogisticRegression()
lr.fit(train_bream_smelt, target_bream_smelt)
print(lr.predict(train_bream_smelt[:5])) #['Bream' 'Smelt' 'Bream' 'Bream' 'Bream']
어짜피 여기서는 bream이나 smelt밖에없기때문에 이거밖에나올 수가 없음.

print(lr.predict_proba(train_bream_smelt[:5])) # row별로 bream일확률 vs smelt일 확률

print(lr.coef_, lr.intercept_) #[[-0.41581543 -0.59429439 -0.68212298 -1.02045413 -0.76459742]] [-2.25744997] 이것으로 식의 계수, 절편을 알 수 있다.  

decisions = lr.decision_function(train_bream_smelt[:5]) #a* wei  + b*len + c*dia + d*hei + e*wid + f 

보통 양성값의 결과만 보여주잖아, 음성을 보는방법도있다
from scipy.special import expit #calculate probability of negative class

print(expit(decisions)) 음성 class일 확률을 보여준다.

다중분류에 대해 알아보자.

#multi regression
lr = LogisticRegression(C=20, max_iter= 1000) #max_iter: # of repeat. default is 100. As C increases, regulation decreases.
lr.fit(train_scaled, train_target)
C가 올라갈수록 규제 하락, C가 내려갈수록 규제 증가. max_iter는 반복할 횟수.

print(lr.score(train_scaled, train_target)) #0.9411764705882353
print(lr.score(test_scaled, test_target)) #0.875

proba = lr.predict_proba(test_scaled[:5])
print(np.round(proba, decimals = 3))
test_scaled은 input값을 scale맞춰준거임. 그것의 처음 5개의 row들을 어떤 확률로 뭐가나올지 검사하는거야. 그럼 확률의 배열이 반환돼.
round는 딱봐도 반올림인거알지.

print(lr.coef_.shape, lr.intercept_.shape) #(7, 5) where 7 = # of rows(classes), 5 = # of columns(coefs). (7,)
print(lr.coef_, lr.intercept_) #Where 7 is # of classes (Species, target), 5 is # of attributes(Weight, Length, Diagonal, Height, Width. input)
여기서 7과 5가나오는데, 7은 target array로 우리가 등록을 했잖아. (lr.fit(train_scaled, train_target) 맞지?) 그거의 distinct한 값의 수야. 여기서는 print(kn.classes_) #'Bream' 'Parkki' 'Perch' 'Pike' 'Roach' 'Smelt' 'Whitefish' 즉 7개의 값이있어. 그래서 7이고, 5는 input의 종류야. csv파일에서 fish_input = fish[['Weight','Length','Diagonal','Height','Width']].to_numpy() 저 5개의 값들을 불러왔기때문에 총 5개야.

****coef, intercept가 주어지면 Z를 구할 수 있다. 그것으로 probability를 구할때 소프트/시그모 중 하나 쓰는듯? 아 시그모이드는 1/(1+e^(-z)) 엿는데 이걸로하면 모든 합이 1이안나온데, 대신 softMax라는 s1 = e^(z1)/(e_sum) s2= e^(z2)/(e_sum) ... 이렇게 구하라고하네..

e_sum = e^(z0) + e^(z1) ... + e^(zN)까지 다더한거임..ㄷㄷ 이제 이해했네.
당연히 predict_proba 값과 같음. 왜냐면 softmax는 coef, intercept, decision(Z), 그것을 softmax라는 함수를 이용해서 확률을 구하는거기때문에. predict_proba는 저걸 하나의 function으로 함축한거네

decision = lr.decision_function(test_scaled[:5])
print(np.round(decision, decimals= 2))

proba = softmax(decision, axis=1)
print(np.round(proba, decimals=3))   #calculate probability with softmax using Z values(decision)

이렇게하는건데 아랫코드랑 결과값이 똑같음
proba = lr.predict_proba(test_scaled[:5]) 
print("lr.predict_proba",np.round(proba, decimals = 3)) 

16. machineLeraning8 
점진적학습: 데이터가 계속들어올때 기존에있던것에 추가한후 다시 훈련을 한다. 서비스중인걸 중단하고 다시 업데이트
온라인학습(서비스중에 업데이트가능) -> 확률적경사하강법... 머라는지모르겟다. stochastic gradient descent SGD -> 최적화방법 . 무작위하게 경사를 내려가는 방법을 찾는법이라는 뜻으로 번역가능. 점진적으로 천천히 내려간다. 
샘플(확률적)하나씩 꺼내서 훈련(경사)시킨다->(반복)-> 훈련세트에 있는 샘플을 다썼다면-> 1에포크(epoch) 완료. 텅빈 훈련세트를 다시 채워서 2epoch 실행..반복
.. 하나씩 꺼내는거말고 여러개씩꺼내는건 미니배치경사하강법(2의배수.. 한번에 전부 꺼내기는 배치경사하강법 이라고한다.

손실함수: 머신러닝알고리즘이 얼마나 나쁜지 측정 (낮을수록 좋은 알고리즘)
미분가능한 함수로 해야한다.ㅋ-> 로지스틱 손실함수...
회귀에서는 평균 제곱, 절대값오차 함수를 사용가능(미분가능) 그래서 손실함수 = 측정지표
분류에서는 정확도로 성능을 측정, 로지스틱함수로 최적화측정

로지스틱손실함수. 예측확률:0~1의값.
-log0.2 와 -log0.8로 실험해보든지.
정답이 1일때:-log(예측확률)
값이 1에 근접할수록 작음.
값이 0에 근접할수록 큼

정답이 0일때:-log(1-예측확률) 
값이 0에 근접할수록 작음.
값이 1에 근접할수록 큼.

따라서 어떤 정답이든 예측값이 정답이랑 멀수록 값이 크다는것을 알 수 있다. 그래서 그값이 작은것을 찾아야 손실이작음. 크로스엔트로피손실함수라고도 부른다.

데이터전처리하는중 반드시!! 스케일을 맞춰줘야한다. 
에포크가 많아질수록 과대적합이되고 너무적으면 과소적합이라고한다. 

이건그냥 알아낸건데 DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel() 이런 애러가뜨면 저기서 시키는데로 마지막에 .ravel()붙이면되드라..

아무튼 이번에는 얼마나 학습하는게 가장 효율적이고 정확한지 알아볼거야
반드시 데이터를 전처리해서 분석해야해


from sklearn.linear_model import SGDClassifier #stochastic gradient descent. epoch epoch epoch. train train train.


sc = SGDClassifier(loss='log', max_iter=20, random_state=42) #max_iter = # of epoch (how many times repeat) max_iter는 반복할 횟수. random_state는 아무거나해도됨 회귀문제일때는 SGDRegressor을 쓰면된다. loss=log해줌으로써 로지스틱함수 쓰겠다는 뜻

#get accuracy 정확도측정
sc.fit(train_scaled, train_target.ravel())
print(sc.score(train_scaled, train_target))
print(sc.score(test_scaled, test_target))


#train once more and get accuracy.
sc.partial_fit(train_scaled, train_target.ravel()) #to avoid DataConversionWarning, put .ravel()
print(sc.score(train_scaled, train_target)) 
print(sc.score(test_scaled, test_target))

그냥 fit이랑 pratial_fit이랑 다른점은 fit은 예전거 다버리고 다시 세팅하는반면, pratial_fit은 기존의 것을 유지하면서 점진적으로 추가로 한번 더 훈련할 수 있음

epoch가 많이할 수록 과소적합문제 (train < test) 발생하는데 너무적게하면 과대적합문제 (train > test)기 때문에 적당한 중앙값을 찾는 과정이 필요한데 그것을 '조기종료'라고한다.

sc = SGDClassifier(loss='log', random_state=42) 이렇게 max_iter를 정해주지않고 계속 돌린다.
classes = np.unique(train_target)
for _ in range(0, 300):
  sc.partial_fit(train_scaled, train_target.ravel(), classes = classes)
단, 이때 fit을 미리 해주지않았으므로 partial_fit 해줄때 classes를 언급해줄 필요가있다.

걍뭐대충 여기쯤이다라고 생각하고 epoch를 하나 정한다.

sc = SGDClassifier(loss ='log', max_iter =BEST EPOCH VALUE, tol=None, random_state=42)
sc.fit(train_scaled, train_target.ravel())
print(sc.score(train_scaled, train_target)) 
print(sc.score(test_scaled, test_target))

BEST EPOCH VALUE에 너가 생각하는 EPOCH값을 넣고 돌려본다. tol=None은 뭐 정밀도라는데.. 그냥써야하나.. 저걸 안쓰면 과대/과소가 뒤바껴..다른때는 몰라도 최적의 에포치를 넣는곳에서라도 써주자.

얘는 머신러닝알고리즘이아니라 머신러닝알고리즘을 최적화하는 방법임. epoch를 구하는 과정은 확률적경사하강법를 몇번해야 가장 정확한지를 알기위해 하는건가보다. 확률적경사하강법은 새로운 데이터가 들어왔을때 그것을 이용해서 다시 훈련하는거고..

17.machineLearning9
이진분류 결정트리

wine = pd.read_csv('https://bit.ly/wine_csv_data')
# wine.head() #pandas로 불러온거를 .head(N)하면 가장  처음N개의 row를 return하는데 기본값은 5다.

wine.info() #말그대로 csv의 정보를 줌. 총 몇개의 값이 있는지, column 종류 별로  NOT NULL 인게 몇개인지, 데이터타입은 어떤건지.

wine.describe() #이거는 더 세부적인것을 알 수 있다. Column별로 count, mean, std, min, max, 25% 50% 75%의 값들을 알려준다.

다시한번 복습하는 전처리과정
1. 데이터를 분류한다 (데이터값들과 클래스값들로) data, target
2. 스케일을 맞춰준다.
3. LogisticRegression에 세팅한다.
wine_data = wine[['alcohol','sugar','pH']].to_numpy()
wine_target = wine[['class']].to_numpy()
train_input, test_iput, train_target, test_target = train_test_split(
  wine_data, wine_target, test_size=0.2, random_state = 42    
) test_Size = 20%임 80%를 훈련하는데 쓴다느거야

ss= StandardScaler()
ss.fit(train_input)
train_scaled = ss.transform(train_input)
test_scaled = ss.transform(test_input)

이거가지고 한번 LogisticRegression을 해보면 잘되지만, 정답 확률이 낮게나와. 서로다른 계수들이 어떻게 동작하는지 찾기어려워? 

lr = LogisticRegression()
lr.fit(train_scaled, train_target.ravel())

print(lr.score(train_scaled, train_target))
print(lr.score(test_scaled, test_target))

print("coefs and intercept: ",lr.coef_, lr.intercept_)

그래서 이거보다는 DecisionTree를 써보자.

dt = DecisionTreeClassifier(random_state =42) #랜덤저거 굳이 안써도됨!
dt.fit(train_scaled, train_target)

print(dt.score(train_scaled, train_target))
print(dt.score(test_scaled, test_target))

plt.figure(figsize=(10,7)) #이건 그냥 시각적으로 크게보여주게하는거
plot_tree(dt)
plt.show()

plot_tree(dt, max_depth = 1, filled=True, feature_names=['alcohol', 'sugar','pH']) 
	루트~자식깊이1까지만   양/음성 색깔구분     사용된특성이름을 표시해줌. 훈련데이터 column순서대로 해줘야해
values = [음, 양성의 개수] 여기서 음양은 현재노드에 밑에있는 음양이라는거임. 여기서 양성이라고떠도 그밑에 음성이뜰수있고 음성이라고떠도 그밑에 양성이잇을수도 있는거야. a 밑에 b,c가있다면 a value는 a밑에잇는 총 음/양성수를 나타내. b가 a의 왼쪽이고 c가 a의 오른쪽이어도, b밑에 양성이 있을 수 있는거고 c밑에 음성이 있을수 있는거야.
samples= 이 아래있는 노드들의 수
Attributes <=?? 왼쪽오른쪽나누는기준
gini = 불순도 = 1 - (음성클래스비율^2 + 양성클래스비율^2) = 1 - ( ( value[0]/sample  )^2  + ( value[1]/sample )^2) = 결국 음/양성 비율이 같을 수록 불순도는 커지고 한쪽으로쏠리면 불순도가 낮아진다. 

지니불순도가 0.5일때 가장 불순한것, 0일때 가장 순수한것. 가장 순수해질때까지 분할한다. 지니불순도가 큰쪽으로 자식노드를 배당함.

결정트리는 딱히 뭐 가중치도없고 그래프도 없어서 전처리를 안해도된다고한다.. (스케일을 맞추지않아도된다는소리임!!!!!)  맞추나안맞추나 늘 값이 같다고한다.

max_depth가 올라갈수록 정답률이 상승하는건 세상의 이치지.

dt.feature_importances_ 로 어떤 attribute가 가장 중요했는지 알 수 있다. 값이 높은 쪽 index의 column이 가장 중요한 역할을 하는것임! 가장 중요하다는 말은 그값에따라 음양이 갈린다는것,

결정트리는 설명/이해/도면하기쉽고 중요도도 나타내기때문에 좋다.

이러면 진짜 어디 느티나무같은 트리가그려져.. 보면 그냥 if( ) {  } else {  }이런식의 2개의 경로가있어. 쭉쭉내려가서 결정하는듯..

분류: 마지막 리프모델샘플의 주위에 있는게 예측하는 타겟이됨.
회귀: 마지막 리프모델샘플의 주위에 있는 값들의 평균이 예측하는 타겟이됨.


18. machineLearning10
1.훈련세트 -> 검증세트 -> 테스트세트 로 3단계검증을 거치자.

train_input, test_input, train_target, test_target = train_test_split(
  wine_data, wine_target, test_size=0.2, random_state = 42    
)

sub_input, val_input, sub_target, val_target = train_test_split(
    train_input, train_target, test_size = 0.2, random_state = 42
)

훈련세트를 나눠 찐훈련/검증세트를 만든다.
이걸 남발하면 훈련세트에만 집중이되면 실전에 투입했을때 테스트의 점수가 떨어질 수 있어.. 그래서 조심해야해. 

2. 교차검증
훈련세트가 크지않다면 쓰기좋음. 검증세트로 나눠놓은 찐훈련세트로 dt를 세팅!.

dt = DecisionTreeClassifier(random_state=42)
dt.fit(sub_input, sub_target)

기본적으로 5번개의 폴드를 나누어서 계속검증

from sklearn.model_selection import cross_validate

scores = cross_validate(dt, train_input, train_target)
print(scores) #{'fit_time': array([0.01016831, 0.01144958, 0.01083636, 0.01061463, 0.01015091]), 'score_time': array([0.00115371, 0.00229836, 0.00120664, 0.00115013, 0.00127244]), 'test_score': array([0.86923077, 0.84615385, 0.87680462, 0.84889317, 0.83541867])} 이렇게나오는데 time붙은거는 검증하는데 걸린시간이고 test_score가 신뢰도임.

ML에서는 교차검증을 쓰고 DL에선 검증세트와 훈련세트를 씀.
교차검증은 데이터가 별로없는곳에서나 쓰임.

3.분할기를 사용한 교차검증
교차검증은 매개변수(dt)를 계속바꾸면서 마음에 드는 값이 나올때까지 검증을 해야할 수 잇는데, 그게 귀찮아서 분할기를 사용한 교차검증이라는게 나왔어.

from sklearn.model_selection import StratifiedKFold #이것은 분류를 위한것 , 회귀를 한다면 KFold를 써라.

                               몇개의 폴드를 나눌지 설정하고 cv parameter에 저걸넣어줘.
splitter = StratifiedKFold(n_splits= 10, shuffle= True, random_state = 42)
scores = cross_validate(dt, train_input, train_target, cv = splitter)
# print(scores)

print("cross score",np.mean(scores['test_score'])) 

4.  그리드 서치 (욕망의 탐색아님)
parameter을 바꾸면서 검증을 해야하는데, max_depth와 min_impurity_decrease라는게 있는데 뭐하나 냅두고 뭐하나바꿔서 실험하는게 안된데. 한꺼번에 같이 바꿔서 실험을 해야하는데 그때 그리드서치를 사용한다고해.

from sklearn.model_selection import GridSearchCV #use cross verification over and over again with different parameter

params ={'min_impurity_decrease':[0.0001,0.0002,0.0003,0.0004,0.0005]}
min_impurity_decrease는 부모의 불순도 - 자식의 불순도 값이다. 불순도란 노드의 자식노드의 음/양성이 50:50으로 나뉠수록 최고이고. 한쪽으로 쏠릴수록 불순도가 낮아진다. 불순도를 정보이득이라한다. min_impurity_decrease는 불순도의 최솟값을 설정한다.  불순도의 차이가 저정도도 안되면, 분할하지마! 라는  뜻이라고한다. 가지치기의 일환이라고..

여려개를 테스트하고싶다면 
params ={'min_impurity_decrease': np.arange(0.0001, 0.001, 0.0001),
         'max_depth': range(5,20,1),
         'min_samples_split': range(2,100,10)} 이런식으로 해준다. np.arange(시작, 끝, 증가량) 을 뜻한다.
	min_samples_split은 분할할때 한쪽에 최소한 n개의 자식이안만들어지면, 분할을 하지말라는 뜻이다. 가지치기의 용도로 쓰임.


dt = DecisionTreeClassifier(random_state=42)
gs = GridSearchCV(dt, params, n_jobs = -1)

GridSearchCV는 기본적으로 5번하는데 * params의 원소갯수. 여기서는 5개니까 5*5 = 25번모델을 만들고 실험한다. n_jobs 를 -1로 지정함으로 가능한 많은 코어들을 써라라는뜻. 2,3, 4..뭐 이런걸로 지정해서 n개의 코어를 조합해도됨.

gs.fit(train_input, train_target) #DT를 사용하므로 딱히 SCALE을 맞출 필요는 없는듯하다.

dt = gs.best_estimator_

print("gs.best_estimator_",gs.best_estimator_)
가장 고성능을 내는 param값들을 내포하고있는 dt object를 보여준다. 
print("Gridsearch score:",dt.score(train_input, train_target))
#가장 고성능을 내는 param값들로 dt를 이용해 훈련한 훈련세트의 적중률을 보여준다.
print("best params:",gs.best_params_)
#gs.best_estimator는 dt의 object형태를 가지고 잇는데 얘는 그 params 값들만 보여준다.
print("cross validate results:",gs.cv_results_['mean_test_score'])
#교차검증을 했던 결과의 평균값를 보여준다. 

아 알았따... gs로하는건 그냥 검증세트의 결과라고 할 수 있다고함..  gs는 검증세트로 해보는거고 dt는 train세트로 하기때문에 다른거임. gs에서 쓰는 검증세트는 위에서 n_split으로 나눈거잖아!! split된게 본체 train과 완전 같을 순 없지!!!

5. 그리드서치은 좋은데 예시를 너무 많이만들수있어. parameter 개수의 따라서 계속 새로운 셈플을 만들기때문에, 자원낭비를 할 수 있음. 그래서 그냥 랜덤으로 parameter을 정한뒤 그걸로 n번만 샘플로 만들어줘라고 할 수 있어.

from scipy.stats import uniform, randint
랜덤정수값 0~9까지 rvs로 10개만 생성
rgen = randint(0,10)
print(np.unique(rgen.rvs(10)))

유리수 0~1까지 rvs로 10개만 생성
ugen = uniform(0,1)
print(np.unique(ugen.rvs(10)))


범위만 정해준다. 생성 갯수는 아래 n_iter에서 정한다.
params = {'min_impurity_decrease': uniform(0.0001, 0.001),
          'max_depth': randint(20, 50),
          'min_samples_split': randint(2, 25),
          'min_samples_leaf': randint(1, 25),
          }

from sklearn.model_selection import RandomizedSearchCV #greed search for randomly splited cross verification samples.

랜덤값으로 생성할때는 randomizedSearchCV를 써야한다.
dt = DecisionTreeClassifier (random_state=42)
gs = RandomizedSearchCV(dt, params, n_iter=100, n_jobs=-1, random_state = 42)
n_iter으로 생성할 sample의 숫자를 정한다. 

이렇게하면 광범위를 빠르게 샘플링할 수 있다. grid search는 꽤 많이 쓰인다고한다. 테스트 세트에는 사용하지않고,  ML에서 모델링을 튜닝할때 (최고의 param을 찾을때?)사용하면 좋을것같다.

greed가아니라 grid였넹;;

19. machineLearning11 트리의 앙상블
무작위성으로 트리의 특성을 약간 낮춘다는 공통특징이있다..

a. 랜덤 포레스트 (RandomForestClassifier/Regresssor): 결정트리를 랜덤하게 만들어서 숲을 만드는..
원래 훈련세트를 랜덤하게 샘플링을하여 부트스트랩 샘플을 만든뒤 결정트리를 훈련하는데에 사용, 단 이때 똑같은 원소가 중복될 수 있다. 그리고 훈련세트의 개수와 부트스트랩세트의 원소개수는 같다.  이것을 여러번해서 각각의 결정트리 훈련의 확률의 합/트리개수로 총 예측값을 평균낸다.
특성이 n개가 있으면 sqrt( n )만큼 특성을 선택한다, 그것들로 최선의 특성분할을 선택한다. 이것을 계속반복..이것이 훈련방법이다. 

tree이기때문에 scaled할 필요 없다
from sklearn.model_selection import cross_validate #cross verification which divides a set by 5 subsets for default and test all of them.
from sklearn.ensemble import RandomForestClassifier #randomly use n attributes for sampling and repeat this 100 times for default. Sum of score of all sample/number of trees is the score of randomforest.

#n jobs의 뜻은 컴퓨터가 할 수 있는 최대의 계산을 하라는거인듯.
rf = RandomForestClassifier(n_jobs=-1, random_state= 42)
#return train_score을 true로함으로써 train_score를 받아볼 수 있다.
scores = cross_validate(rf, train_input, train_target, return_train_score=True, n_jobs = -1)
#test_score는 검증세트의 점수이다.
print("train score:",np.mean(scores['train_score']), "test score:",np.mean(scores['test_score']))

#모델을 훈련하기.
rf.fit(train_input, train_target.ravel())
#특성을 랜덤하게 선택하다보니 골고루 각각의 특성을 사용해서 다른곳에서 낮은 점수가나온 특성도 높게될수있고 높ㅍ게나온것도 낮게될수있음.
print("importances:",rf.feature_importances_)

#OOD는 랜덤으로 차줄되지않은 샘플들의 집합.
rf = RandomForestClassifier(oob_score=True, n_jobs=-1, random_state= 42)
rf.fit(train_input, train_target.ravel())
# 그걸로 rf를 해봤을때 점수는 얼마인지..인가..
print("oob score:",rf.oob_score_)

ravel()은 안붙이면 뭐 이상한 오류가떠서 권고사항에따라붙여줌
->부트스트랩을 사용하여 트리의성능을 억제한다.
b. 엑스트라트리 
from sklearn.ensemble import ExtraTreesClassifier #not using bootstrap, randomly use n attributes to make the best score. very fast, less accurate than randomforest. To gain more accurate score, must increase the number of trees.

et = ExtraTreesClassifier(n_jobs= -1, random_state =42)
scores = cross_validate(et, train_input, train_target, return_train_score =True, n_jobs =-1)

print("train score:",np.mean(scores['train_score']), "test score:",np.mean(scores['test_score']))

et.fit(train_input, train_target.ravel())
print("importances:", et.feature_importances_)

-> 결과는 뭐 random forest랑 비슷비슷해보임. 속도가빠르지만 더 큰 데이터로 평가했을때 랜덤포래스트보단 낮은 정확도를 가진다고한다.

c.그레이디언트 부스팅 (가장급이 높은 알고리즘)
경사하강법맹키로 손실함수의 최저점을 찾음. learning rate로 학습속도를 제어. 깊이가 얕은 일부러 성능낮은 트리사용. 병렬로 하느게아니라 하나씩해야되서 훈련시간은 오래걸린다는 단점.

from sklearn.ensemble import GradientBoostingClassifier #like loss function, find the minimum value of loss function. very useful algorithm. 

et = ExtraTreesClassifier(n_jobs= -1, random_state =42)
scores = cross_validate(et, train_input, train_target, return_train_score =True, n_jobs =-1)

print("train score:",np.mean(scores['train_score']), "test score:",np.mean(scores['test_score']))

et.fit(train_input, train_target.ravel())
print("importances:", et.feature_importances_)

print('GradientBoosting')

gb = GradientBoostingClassifier(random_state = 42)
scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs = -1)
print("tran score:", np.mean(scores['train_score']), "test score:",np.mean(scores['test_score']))

#n_estimator로 트리개수를 늘려준다->손실함수의 낮은 위치로 이동. learning_rate로 더 급격하게 배우게한다. -> 훈련세트의 정확도를 늘려줌. 과대적합은 억제해줌.
gb = GradientBoostingClassifier(random_state = 42, n_estimators=500, learning_rate=0.2)
scores = cross_validate(gb, train_input, train_target, return_train_score=True, n_jobs = -1)
print("tran score:", np.mean(scores['train_score']), "test score:",np.mean(scores['test_score']))
gb.fit(train_input, train_target.ravel())
print('importances:', gb.feature_importances_)

d.히스토그램 기반 그레디언트 부스팅
훈련데이터를 256개구간으로 나눠서 학습함. 굉장히 빠르다. 255개이고 1개는 누락값들 할당지역이기때문에 누락된 데이터가있어도 사용할 수 있다! 빠르고 성능좋은

from sklearn.ensemble import HistGradientBoostingClassifier #divide train set into 256 groups : one group for null attribute and 255 for others.

hgb = HistGradientBoostingClassifier(random_state= 42)
scores = cross_validate(hgb, train_input, train_target, return_train_score= True, n_jobs = -1)
print("train score:", np.mean(scores['train_score']), "test score:",np.mean(scores['test_score']))

e. Permutation Importance : 특성값을 하나씩 섞고 평가를 내고 원래대로 되돌려놓고 다음번 특성을 섞고 평가를 내고... 원래 데이터로 평가를 낸뒤 섞은거랑 비교함.  그래서 어떤걸바꾸었을때 점수가 바뀌는지 비교하여 중요도를 평가함. hgb 와 연동할 수 있음! 왜냐면 hgb에서는 importances를 알 수 없거든. 음 굳이 hgb말고 다른애들과도 연동이된다함!

from sklearn.inspection import permutation_importance #switch one attribute with another and repeat over and over again. Compare the score of switched data and score of the original in order to figure out which attribute is critical.

print('permutation importance for knowing importances of hgb')
hgb.fit(train_input, train_target.ravel())

#n_repeat으로 특성을 섞을 횟수를 정함.
result = permutation_importance(hgb, train_input, train_target, n_repeats= 10, random_state=42, n_jobs = -1)
print('importance:', result.importances_mean)
#importance: [0.08876275 0.23438522 0.08027708] 이렇게나오는데 각 숫자는 n번째 특성을 바꾸었을때 저정도의 점수의 차이가 발생한다라는거임. 숫자가 클 수록 변동이 크다는거니까 중요하다는거지.

result = permutation_importance(hgb, test_input, test_target, n_repeats= 10, random_state=42, n_jobs = -1)
print('importance:', result.importances_mean)

print('hbg score:', hgb.score(test_input, test_target))

f. Gradient boosting 전용 
from xgboost import XGBClassifier #only for gradientboosting!

print('XGBoost') 
xgb = XGBClassifier(tree_method='hist', random_state= 42)
scores = cross_validate(xgb, train_input, train_target, return_train_score=True, n_jobs = -1)
print("train score:",np.mean(scores['train_score']),"test score:", np.mean(scores['test_score']))

from lightgbm import LGBMClassifier #only for gradientboosting!
print('LightGBM')
lgb = LGBMClassifier(random_state=42)
scores = cross_validate(lgb, train_input, train_target, return_train_score=True, n_jobs = -1)
print("train score:",np.mean(scores['train_score']),"test score:", np.mean(scores['test_score']))

앙상블로 심각한 작업을 하고싶다면 그레이디언트부스팅 또는 히스토그램(xgb light)으로 하면된다.

트리앙상블로 더 강력한 훈련을 할 수 있다. 앙상블.predict([[a,b,c]])로 새로운 예측을 할 수 있다! 

20. machineLearning 12 
비지도학습 (사진보고 분류하는거~)
타겟이 없는 문제. 특성데이터만 있을때


!wget https://bit.ly/fruits_300_data -O fruits_300.npy
fruits = np.load('fruits_300.npy')

이런걸이용해서 남이올려놓은 파일에 엑세스할수있다.

이파일은 2차원배열이 여러개있는 3차원배열이다. 
마치 체스판에서 정사각형의 하나의 칸을 나타내는 행과 열로 이루어진 하나의 2차원배열이 여러개있다는말
[
[  [d1x1,d1y1], [d1x2,d1y2].... ],
[  [d2x1,d2y1], [d2x2,d2y2].... ],
[  [d3x1,d3y1], [d3x2,d3y2].... ],
...
]

print("Shape:",fruits.shape) #Shape: (300, 100, 100)

print(fruits[0,0,:]) #이걸로는 첫번째 데이터에 첫번째줄에 대한 모든정보를 가져온다. 
#[  1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   2   1
   2   2   2   2   2   2   1   1   1   1   1   1   1   1   2   3   2   1
   2   1   1   1   1   2   1   3   2   1   3   1   4   1   2   5   5   5
  19 148 192 117  28   1   1   2   1   4   1   1   3   1   1   1   1   1
   2   2   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1   1
   1   1   1   1   1   1   1   1   1   1]

이런모양인데, 숫자가 큰곳이있는경우는 그부분의 색이 흰색이라

plt.imshow(fruits[0], cmap='gray_r')
plt.show()
#아무래도 그림으로 보는게 더 편하니 imshow기능으로 첫번째 데이터를 그려본다. cmap = 'gray_r'은 리버스회색이다. 기본데이터가 배경이 검정이라 보기편하게 리버스시켰다.

2차원배열을 1차원으로 길게 늘려준다. 그냥 다루기가 편하대
apple = fruits[0:100].reshape(-1, 100*100)
pineapple = fruits[100:200].reshape(-1,100*100)
banana = fruits[200:300].reshape(-1,100*100)

# print(apple.shape)


샘플의 평균을 히스토그램으로 나눠보자!
샘플별로 평균내기
plt.hist(np.mean(apple, axis=1), alpha= 0.8)
plt.hist(np.mean(pineapple, axis= 1), alpha = 0.8)
plt.hist(np.mean(banana, axis= 1), alpha =0.8)
plt.legend(['apple', 'pineapple', 'banana']) 
plt.show()
axis =0이면 행에 따라↓보고 1이면 열에따라 → 평균을 낸다.
alpha는 그냥 투명도인듯하다. 이러면 막대모양의 그래프가나온다.
x축은 데이터값들이고 y축은 그 값들의 빈도이다. 

픽셀별로  평균내기
fig, axs = plt.subplots(1,3, figsize =(20,5))  #subplot는 부분그래프를 그린다. 여러그래프를 한이미지에 그릴 수 있게해준다. 1개의 행에 3개의 열을 넣게해준다. 3이니까 axs가 3개가되는거다.. 그냥 plt에서 하나의 행에 3개그래프를 그릴 수 있다는말인듯. figsize는 얼마나 촘촘한지 나타내는듯.. 

axs[0].bar(range(10000), np.mean(apple, axis=0))
axs[1].bar(range(10000), np.mean(pineapple, axis= 0))
axs[2].bar(range(10000), np.mean(banana, axis=0))
plt.show()

이게 막대그래프가 겹쳐보이지만, 그냥 값이 여러개 한거번에 몰려있으면 더 짙게나온다.. 듬성듬성있으면 옅게 보이는데 값이 한곳에 밀집해있으면 짙게보이네.\

바나나를 보면 기다란곳이 가운데는 항상 관통하므로 가운데는 짙고 높은값이 나오는반면, 파인애플은 두루두루 높게나오는것을 알 수 있다.
짙은거 = 값이 여러번 출몰하는곳 
값 = 그 부분의 색감이 어떤지
ㅡㅡㅡ
이미지 전체를 평균을내어 그것을 한번에 그릴려면 이렇게하면된다.
apple_mean = np.mean(apple, axis=0).reshape(100,100)
pineapple_mean = np.mean(pineapple, axis=0).reshape(100,100)
banana_mean = np.mean(banana, axis = 0).reshape(100,100)

fig, axs = plt.subplots(1,3,figsize=(20,5))
axs[0].imshow(apple_mean, cmap ='gray_r')
axs[1].imshow(pineapple_mean, cmap='gray_r')
axs[2].imshow(banana_mean, cmap = 'gray_r')
plt.show()
ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ
사과 100개 이미지 보여주기 
abs_diff = np.abs(fruits - apple_mean) #diff 총 과일 데이터에서 사과의 평균값을 빼준다.
abs_mean = np.mean(abs_diff, axis=(1,2)) #그리고 그 데이터의 1번째 2번째 축으로 (0번째 축은 샘플의 행이므로 제외) 평균을 내준다.

print(abs_mean.shape) #그럼 이건 300개의 평균으로 이루어진 행이된다.

apple_index = np.argsort(abs_mean)[:100] #평균값이 낮은순으로 100개만 정렬을한다. 사과의 평균을 뺐기때문에 0에 가까운것들이 사과가 될것이다. 왜냐면 사과-사과일테니.

fig, axs = plt.subplots(10,10, figsize=(10,10))
for i in range(10):
  for j in range(10):
    axs[i,j].imshow(fruits[apple_index[i*10+j]], cmap='gray_r') #apple_index에는 사과밖에없다. i*10+j번째의 사과를 fruit array에서 축출할수있다. 저렇게하면 apple_index에있는 사과가 fruit에서 검색되어 출력된다. i*10+j로 0에서 99까지의 사과를 가져올 수 있다.
    axs[i,j].axis('off')
plt.show()

비슷한거끼리 모아놓는것을 군집 클러스터링이라고한다. 
모아논 집단은 클러스터라고 부른다.

21. k평균
타겟이 없는 비지도학습

하이퍼파라미터를 미리지정하여 몇개의 클러스터로 나눌지 정해준다. 
그러면 처음에는 무작위로 클러스터를 중심을 기준으로 묶는다. 
그러고 그 클러스터의 평균을 낸다. 그러면 그 평균이 그 값과 더 가까운 쪽으로 이동하여
결국에는 잘 맞는 애들끼리 모여있는곳으로 중심이 이동하여, 올바른 클러스터가 이루어진다.

from sklearn.cluster import KMeans #set n number of cluster. First, randomly group elements and get mean of them. Then group again with the mean and then get mean value of them again. Repeat this process until all clusters form propery.

km = KMeans(n_clusters=3, random_state = 42) #3개의 군집으로 나누어준다(센트로이드라고도 한다) 기본적으로 n_iter는 10으로 설정되어있다.
km.fit(fruits_2d) #어떤 축을 지정하지않고 그냥 array를 넣어준다.

print(km.labels_) #각각 어떤 것들로 분류되었는지를 나타낸다

print(np.unique(km.labels_, return_counts= True)) #군집유형을 보여준다. 여기서는 k=3이므로 0, 1,2가 나온다. return count는 딱봐도 해당 군집에 몇개의 element가있는지 보여주는듯


def draw_fruits(arr, ratio=1):
  n = len(arr) #n= 샘플의 개수
  rows = int(np.ceil(n/10)) # 한줄에 10칸씩할거기때문에 10으로 나눈다. 그것을 올림해준다. 왜냐면 11칸이어도 줄은 2줄이기때문에. 11/10 =1.1 -> 2. 첫줄에 10개, 두번째줄에 1개.

  cols = n if rows <2 else 10 #rows가 1줄일경우, cols = n 이고 아닐경우 10이라는 소리다.

  fig, axs = plt.subplots(rows, cols, figsize=(cols*ratio, rows*ratio), squeeze=False)

  for i in range(rows):
    for j in range(cols):
      if i*10 + j < n:
        axs[i,j].imshow(arr[i*10+j], cmap='gray_r')
      axs[i,j].axis('off') #이거 안하면 샘플에 테두리가쳐져. 그거 보기싫으니까 끄는거임

  plt.show()

draw_fruits(fruits[km.labels_ ==0]) #cluster 0~2중 첫번째 군집을보여줘~


draw_fruits(km.cluster_centers_.reshape(-1,100,100), ratio= 3) #군집의 중앙값 array를 100*100 3차원으로 만들어본다. 그러면 평균값으로 이루어진 군집대표 3장이 나오는데 그걸 그리기, ratio는 그냥 그림 크기야. 

print(km.transform(fruits_2d[100:101])) #여기서 100:101은 2차원 배열을 얻기위해서 그러는거임. 100번째 열에있는걸 가져오겠다는건데, 이렇게하지않고 [100]이라면 1차원배열이 출력됨. 100~101이라는 범위를 둠으로써 [ [ ] ]모양의 2차원 배열이 반환됨.  아무튼 얘는 [[3393.8136117  8837.37750892 5267.70439881]]이런 값을 반환해주는데, 클러스터까지의 거리를 나타낸다고함. 아마 그 거리가 가장 작은게 가까우니까 가장가까운 클러스터에 속한다는거임.

print(km.predict(fruits_2d[100:101])) #fruits_2d에서 100번째 과일은 어떤 군집에 속할까를 예측 

draw_fruits(fruits[100:101]) #그릴때는 항상 3차원으로. 

최적의 k 찾기
inertia = []
for k in range(2,7):
  km = KMeans(n_clusters= k, random_state =42)
  km.fit(fruits_2d)
  inertia.append(km.inertia_)

plt.plot(range(2,7), inertia)
plt.xlabel('k')
plt.ylabel('inertia')
plt.show()

그래프에서 딱 꺾이는 지점이 최고의 k값이라고한다.
print(km.n_iter_) 

k평균의 최대단점이 cluster의 수를 미리정해야하는점인데, 위의 그래프로 그 단점을 약간 보완할 수 있다.

만족스럽지않다면 지도학습을 통해 현실적인 값을 찾을 수 있게 도와준다.

22. 주성분분석
machineLearning 14 

차원축소 
일반적으로는 (2차원이상의 배열에선 축(axis)을 차원이라고한다.) 1차원배열(백터)에서는 원소의 갯수를 차원이라고 부른다.

하지만 예를들어 2차원배열의 특성이 3개라면 하나의 특성을 하나의 백터로봐서 그래프로 그린다면 3차원그래프가 그려질 수 있다. 차원축소한다는것은 이 특성(벡터)의 개수를 줄인다는것을 의미한다. 

주성분분석 Principal주요한 Component성분 Analysis분석
가장많이 퍼져있는 쪽을 찾는다 (데이터들이 공통적으로 관통하는 선을 찾는다).
이때 2개의 특성(축)으로 이루어진것에서 하나의 축(주성분)을 찾기때문에 2개의 특성을 하나의 특성(주성분)으로 '축소'한다는것이다.

또 하나의 주성분을 찾을 수 있는데, 이때는 원래 찾은 주성분에 수직인 것이 또 하나의 주성분이다.


pca = PCA(n_components= 50) #0~300개의 샘플이있는데 한 50개만 주성분을 찾아봐라
pca.fit(fruits_2d)

print(pca.components_.shape) #(50, 10000) 50개의 행 10000개의 열. 50개의 주성분은 100*100의 특성(픽셀)에서 나왔다는 뜻.

draw_fruits(pca.components_.reshape(-1, 100, 100)) #주성분을 그리기

print(fruits_2d.shape) # 300, 10000임 왜냐면 얘는 fruits_2d = fruits.reshape(-1, 100*100) 이건데 샘플이 300개잇어.

fruits_pca = pca.transform(fruits_2d) #300,10000을 50개의 주성분으로 변환하기. 여기서 transform이 있다는것은 다른 분류기와 사용할 수 있다는 것이야. 예를 들어 LogisticRegression.
print(fruits_pca.shape) #300,50

50개의 주성분으로 줄였던것을 다시 10000개의 특성으로 변환하기. 단, 이때는 데이터 손실이 발생할 수 있다. 50/10000 = 1/200 이기때문에 저정도 손실이 발생한다.
fruits_inverse = pca.inverse_transform(fruits_pca)
print(fruits_inverse.shape) #300,10000

fruits_reconstruct = fruits_inverse.reshape(-1, 100,100) 
draw_fruits(fruits_reconstruct)

print(np.sum(pca.explained_variance_ratio_)) 어느정도의 분산을 유지했는지 알려준다. 0.92가 나왔는데, 92퍼정도의 정확도를 가졌다는뜻? 

plt.plot(pca.explained_variance_ratio_) #component수에 따라 얼마정도의 분산을 가지고 있는지 보여준다
plt.show()

분류기와 함께 사용해보자. 왜냐면 pca는 predict가 없다.. 그래서 이렇게 주성분을 찾고 그것으로 다른 분류기에 계산을 돕는다..

lr = LogisticRegression() #자꾸 max_iter을 올리라하는데 시원하게 1000으로 올려주엇다.lr = LogisticRegression(max_iter = 1000)
target = np.array([0]*100+[1]*100+[2]*100) #answer sheet

scores = cross_validate(lr, fruits_2d, target)
print('test score original',np.mean(scores['test_score']))

print('fit time original',np.mean(scores['fit_time']))

scores = cross_validate(lr, fruits_pca, target)
print('test score pca 50',np.mean(scores['test_score']))

print('fit time pca 50',np.mean(scores['fit_time']))

test score original 0.9966666666666667
fit time original 1.5076923370361328

pca로 했을대 시간은 훨씬감축되고 정확도는 올라간것을 볼 수 있다. 왜냐면 original에서는 가중치가 많이부여되고 픽셀도 10000개나 되지만 주성분을 찾으면(pca) 50개밖에안되어 계산이빠르다.
test score pca 50 1.0
fit time pca 50 0.039377880096435544

ㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡㅡ


pca = PCA(n_components = 0.5) #이렇게 실수를 넣으면 주성분을 0.5개찾아줘가아니라 분산의 비율이 0.5가 될때까지 찾아줘다.
pca.fit(fruits_2d)
print(pca.n_components_) #그럼 여기서 2가 나오는데, 주성분 2개만으로도 10000개의 픽셀을 표현할 수 있다는뜻이다..ㄷㄷ 여기서 주성분이 2개라는것은 [  , ] 이렇게 표현 가능하다는거임. 아까 50개했을때는 [ , , , , , , ,... ., ,, , ,]이런식으로 표현됨

fruits_pca = pca.transform(fruits_2d)
print(fruits_pca.shape)

scores = cross_validate(lr, fruits_pca, target)
print('test score pca 0.5',np.mean(scores['test_score']))

print('fit time pca 0.5',np.mean(scores['fit_time']))

test score pca 0.5 0.9933333333333334
fit time pca 0.5 0.04951310157775879 결과는 이렇게나오는데 나름 괜찮은 점수이다.

ㅡㅡㅡ
군집(cluster)과 함께 사용하기
km = KMeans(n_clusters =3, random_state = 42)
km.fit(fruits_pca)

print(np.unique(km.labels_, return_counts= True)) 
#(array([0, 1, 2], dtype=int32), array([110,  99,  91])) 여기서 정확도가 100퍼센트가 아닌이유는 cross validate 햇을때 lr에서 100퍼랬지 여기서 km에선 아님...... 그래서 막몇개 섞여있따.

시각화하기. 주성분이 2개라 모든 행(모든 샘플)을 표시하고, x축에는 주성분중 1번째, y축에는 주성분중 2번째 특성을 표시함으로써 데이터의 모양들을 알 수 있다.
for label in range(0, 3):
  data = fruits_pca[km.labels_ == label]
  plt.scatter(data[:,0], data[:,1])
plt.legend(['apple', 'banana', 'pineapple'])
plt.show()


23. 딥러닝시작
machineLearning 15

패션 MNIST
케라스에 연습예제가 있다고한다. 
from tensorflow import keras

(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()

이렇게 두개의 쌍으로 리턴해주기때문에 좋다.


print(train_input.shape, train_target.shape)

print(test_input.shape, test_target.shape)

각각 
(60000, 28, 28) (60000,)
(10000, 28, 28) (10000,) 이렇게나온다.입력에는 60000개의 샘플이 (하나당 2개의 특성으로 이루어진)들이있고 타겟에는 1개의 답이있다 (당연하지)

이걸로 훈련세트 처음 10개만 출력해본다. 
fig, axs = plt.subplots(1, 10, figsize= (10,10))
for i in range(10):
  axs[i].imshow(train_input[i], cmap='gray_r')
  axs[i].axis('off')
plt.show()

0~255의 색중 0일수록 어둡고 255일수록 밝다. 단, 여기서는 색감반전을 해서 0일수록 밝게해준다. 육안으로 보기 편하게


print([train_target[i] for i in range(10)])

print(np.unique(train_target, return_counts =True))

#[9, 0, 0, 3, 0, 2, 7, 2, 5, 5] 훈련세트 처음10개의 정답
#(array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8), array([6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000, 6000])) 각 정답당 6천개씩 할당되어있다고한다.

딥러닝에서 픽셀값은 255로 나눠 0~255의 범위를 0~1로줄여준다. 그리고 3차원데이터를 2차원으로 만들어준다.
train_scaled = train_input / 255.0
train_scaled = train_scaled.reshape(-1, 28*28)

print(train_scaled.shape) #(60000, 784) 

그것을 경사하강법을 사용한 로지스틱회귀를 사용해준다. 그것을 교차검증으로 정확도를 한번 봐본다. 정답의 종류(클래스)가 10개이므로 다중분류이다. (2개이면 2중분류). 그것을 5개의 폴드로 5번검증세트로 나누어 검증해본다.
sc = SGDClassifier(loss='log', max_iter= 5, random_state= 42)

scores = cross_validate(sc, train_scaled, train_target, n_jobs =-1)
print(np.mean(scores['test_score']))

원리는 
샘플데이터-> 각각의 계수를 곱하기 -> 각각의 Z (이것은 하나의 데이터당 클래스의 종류개수만큼) 그것을 데이터의개수만큼하기. z를 뉴런이라고 부른다.

이렇게 생성된 z들을 소프트맥스 함수로 계산해준다.

교차검증을 사용하지않고, 케라스로 모델을 만들수 있다. 왜냐면 계산비용이 늘어나니까. 데이터가 너무많아. 그래서 그냥 검증세트를 20퍼정도 띄어놓고 해도됨.
train_scaled, val_scaled, train_target, val_target = train_test_split(
    train_scaled, train_target, test_size = 0.2, random_state = 42
)

print(train_scaled.shape, train_target.shape)

print(val_scaled.shape, val_target.shape)

#잘띄어졌다.(48000, 784) (48000,)
(12000, 784) (12000,) 여기서 784는 28*28

			
dense = keras.layers.Dense(10, activation='softmax', input_shape=(28*28,))
클래스종류가 10개기때문에 10층이다. 모든 데이터가 모든층에 빢빡하게 연결되어서 ? fully connected layer라고 부른다.. 출력층은 클래스개수와 항상 같다. 다중분류이기때문에 softmax를 사용한다. 2진분류일경우 sigmoid를 쓰면된다고한다. input shape의 크기는 샘플의 크기다. 크기가 개수가아니라, shape에서 (개수, 크기)로나온다. 

model = keras.Sequential(dense)
model.compile(loss ='sparse_categorical_crossentropy', metrics ='accuracy')

정확도를 기록하고 싶다면 metrics= accuracy를 넣어준다.
손실도를 기록하고싶다면 loss = sparse_categorical_crossentropy를 해주는데, 이진 분류일경우 binary_crossentropy를 해준다.
sparse가 붙은이유는 원핫인코딩이 안되어있을경우 타깃값을 정수로 저장하기위해쓴다.원핫인코딩(타깃인것만 1, 나머지는 0으로 저장함)이 되어있을경우쓰지않는다., 

print(train_target[:10]) #[7 3 5 8 6 9 3 3 9 9]

model.fit(train_scaled, train_target, epochs= 5)
#Epoch 1/5
1500/1500 [==============================] - 3s 1ms/step - loss: 0.6082 - accuracy: 0.7938
Epoch 2/5
1500/1500 [==============================] - 2s 1ms/step - loss: 0.4788 - accuracy: 0.8400
Epoch 3/5
1500/1500 [==============================] - 2s 1ms/step - loss: 0.4567 - accuracy: 0.8485
Epoch 4/5
1500/1500 [==============================] - 2s 1ms/step - loss: 0.4445 - accuracy: 0.8529
Epoch 5/5
1500/1500 [==============================] - 2s 1ms/step - loss: 0.4367 - accuracy: 0.8561

애포크가 올라갈수록 손실도가 떨어지고 정확도가 올라간다..

검증세트를 평가해본다. 나름 85퍼정도로 ㄱㅊ게나온다.
print(model.evaluate(val_scaled, val_target))
375/375 [==============================] - 1s 1ms/step - loss: 0.4538 - accuracy: 0.8495, [0.45378515124320984, 0.8495000004768372] 

오늘 배운것은 딥러닝에서는 사이킷런의 로지스틱함수를 써도되겠지만 케라스모델을 쓰는데, 케라스모델은 층을 만드는부분과 모델을 만드는 부분을 설정해줄 수 잇게 태생적으로 만들어져있다고한다. 다양한 실험을 할 수 있다는 장점이있다.

24. 




 
